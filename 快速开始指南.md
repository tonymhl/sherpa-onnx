# 🚀 Sherpa-ONNX TTS 快速开始指南

## 📌 概述

本指南将帮助您在 **5分钟内** 完成 sherpa-onnx TTS 模型的部署和测试。

## ⚠️ 重要提示

**vits-melo-tts-zh_en 模型兼容性问题**：
- 该模型在某些 sherpa-onnx 版本中可能出现 `vits-dict-dir` 错误
- 如果遇到问题，请查看 `故障排除指南.md`
- 推荐使用替代模型（见下方）或升级 sherpa-onnx 到最新版本

**推荐的替代模型**：
- 英文：`vits-piper-en_GB-cori-medium`
- 中文：`vits-icefall-zh-aishell3`
- 测试工具：`python test_tts_alternative.py`

---

## 🪟 Windows 快速开始

### 准备工作（一次性）

1. **安装 Python 3.8+**
   - 下载地址：https://www.python.org/downloads/
   - 安装时勾选 "Add Python to PATH"

2. **验证 Python 安装**
   ```powershell
   python --version
   ```
   应该显示 Python 3.8 或更高版本

### 方案A：在线安装（适合有网络的环境）

```powershell
# 1. 安装 sherpa-onnx
pip install sherpa-onnx soundfile

# 2. 下载模型
python download_model.py

# 3. 运行测试
python test_tts.py
```

**完成！** 您应该会看到生成了几个 `.wav` 音频文件。

### 方案B：离线部署（适合无网络或需要打包）

```powershell
# 1. 创建工作目录
mkdir D:\tts-deploy
cd D:\tts-deploy

# 2. 下载依赖包（在有网络的机器上）
pip download sherpa-onnx soundfile -d packages

# 3. 下载模型（在有网络的机器上）
python download_model.py

# 4. 打包整个目录
#    - 复制到目标机器
#    - 在目标机器上运行：

# 5. 离线安装依赖
pip install --no-index --find-links=packages sherpa-onnx soundfile

# 6. 运行测试
python test_tts.py
```

---

## 🐧 Linux/CentOS 快速开始

### 准备工作（一次性）

```bash
# CentOS 7
sudo yum install -y python3 python3-devel gcc gcc-c++ make

# CentOS 8/Stream
sudo dnf install -y python3 python3-devel gcc gcc-c++ make
```

### 在线安装

```bash
# 1. 安装 sherpa-onnx
pip3 install sherpa-onnx soundfile

# 2. 下载模型
python3 download_model.py

# 3. 运行测试
python3 test_tts.py
```

### 离线部署

```bash
# 1. 解压部署包
tar -xjf tts-deploy-package.tar.bz2
cd tts-deploy-package

# 2. 运行部署脚本
chmod +x deploy_centos.sh
./deploy_centos.sh
```

---

## 🎯 基础使用示例

### Python 代码示例

```python
import sherpa_onnx
import soundfile as sf

# 1. 配置模型
config = sherpa_onnx.OfflineTtsConfig(
    model=sherpa_onnx.OfflineTtsModelConfig(
        vits=sherpa_onnx.OfflineTtsVitsModelConfig(
            model="./vits-melo-tts-zh_en/model.onnx",
            lexicon="./vits-melo-tts-zh_en/lexicon.txt",
            tokens="./vits-melo-tts-zh_en/tokens.txt",
        ),
        num_threads=4,
        provider="cpu",
    ),
)

# 2. 创建 TTS 对象
tts = sherpa_onnx.OfflineTts(config)

# 3. 生成语音
text = "你好世界，Hello World！"
audio = tts.generate(text, sid=0, speed=1.0)

# 4. 保存音频
sf.write("output.wav", audio.samples, samplerate=audio.sample_rate)

print("✅ 音频已保存到 output.wav")
```

### 命令行使用（如果已编译 C++ 版本）

```bash
# 使用命令行工具
sherpa-onnx-offline-tts \
  --vits-model=./vits-melo-tts-zh_en/model.onnx \
  --vits-lexicon=./vits-melo-tts-zh_en/lexicon.txt \
  --vits-tokens=./vits-melo-tts-zh_en/tokens.txt \
  --output-filename=output.wav \
  "你好世界"
```

---

## 📝 常用参数说明

### 语速控制

```python
# 正常速度
audio = tts.generate(text, speed=1.0)

# 加快 50%
audio = tts.generate(text, speed=1.5)

# 减慢 20%
audio = tts.generate(text, speed=0.8)
```

### 线程数优化

```python
# 根据 CPU 核心数调整
config = sherpa_onnx.OfflineTtsConfig(
    model=sherpa_onnx.OfflineTtsModelConfig(
        vits=...,
        num_threads=4,  # 推荐：CPU核心数的 50-80%
    ),
)
```

### 音频质量

```python
# 保存为 WAV 格式（最高质量）
sf.write("output.wav", audio.samples, 
         samplerate=audio.sample_rate, 
         subtype="PCM_16")

# 保存为 FLAC 格式（无损压缩）
sf.write("output.flac", audio.samples, 
         samplerate=audio.sample_rate)

# 保存为 OGG 格式（有损压缩，文件小）
sf.write("output.ogg", audio.samples, 
         samplerate=audio.sample_rate)
```

---

## 🔧 故障排除

### 问题1：找不到模型文件

**错误信息**：
```
❌ 错误：找不到模型目录 'vits-melo-tts-zh_en'
```

**解决方案**：
```bash
# 下载模型
python download_model.py

# 或手动下载
# https://github.com/k2-fsa/sherpa-onnx/releases/download/tts-models/vits-melo-tts-zh_en.tar.bz2
```

### 问题2：导入 sherpa_onnx 失败

**错误信息**：
```
ModuleNotFoundError: No module named 'sherpa_onnx'
```

**解决方案**：
```bash
# 重新安装
pip install sherpa-onnx

# 或离线安装
pip install --no-index --find-links=packages sherpa-onnx
```

### 问题3：生成速度慢

**表现**：RTF > 1.0（实时率大于1）

**解决方案**：
1. 增加线程数：`num_threads=8`
2. 减少文本长度：每次合成不超过 500 字
3. 使用更快的 CPU 或升级硬件

### 问题4：中文发音不正确

**解决方案**：
- 检查 `lexicon.txt` 文件是否完整
- 对于专业术语，可能需要手动添加到词典
- 参考：https://github.com/k2-fsa/sherpa-onnx/pull/1209

---

## 📊 性能参考

| 硬件 | CPU | 线程 | RTF | 评价 |
|------|-----|------|-----|------|
| 树莓派 4 | Cortex-A72 | 4 | 0.16 | 可用 ✔️ |
| 笔记本 | Intel i5 | 4 | 0.10 | 良好 ✅ |
| 服务器 | Intel Xeon | 8 | 0.05 | 优秀 🚀 |

**RTF 说明**：
- RTF < 0.3: 优秀，可以流式播放
- RTF < 1.0: 合格，可以实时合成
- RTF > 1.0: 较慢，需要等待

---

## 📚 进阶功能

### 批量合成

```python
texts = [
    "第一句话",
    "第二句话",
    "第三句话",
]

for i, text in enumerate(texts):
    audio = tts.generate(text)
    sf.write(f"output_{i}.wav", audio.samples, 
             samplerate=audio.sample_rate)
```

### 多线程并发

```python
from concurrent.futures import ThreadPoolExecutor

def generate_audio(text, filename):
    audio = tts.generate(text)
    sf.write(filename, audio.samples, samplerate=audio.sample_rate)
    return filename

texts_and_files = [
    ("文本1", "audio1.wav"),
    ("文本2", "audio2.wav"),
    ("文本3", "audio3.wav"),
]

with ThreadPoolExecutor(max_workers=3) as executor:
    futures = [executor.submit(generate_audio, text, file) 
               for text, file in texts_and_files]
    
    for future in futures:
        print(f"✅ 完成: {future.result()}")
```

### 实时流式合成（高级）

参考官方文档：https://k2-fsa.github.io/sherpa/onnx/tts/

---

## 🔗 相关资源

- **官方文档**：https://k2-fsa.github.io/sherpa/onnx/tts/
- **GitHub 仓库**：https://github.com/k2-fsa/sherpa-onnx
- **模型下载**：https://github.com/k2-fsa/sherpa-onnx/releases/tag/tts-models
- **在线演示**：https://huggingface.co/spaces/k2-fsa/text-to-speech

---

## 💡 使用建议

1. **首次使用**：从 Python API 开始，最简单易用
2. **生产环境**：考虑编译 C++ 版本，性能更好
3. **离线部署**：提前下载好所有依赖包和模型
4. **性能优化**：根据 CPU 核心数调整线程数
5. **长文本**：分段合成，避免一次合成过长文本

---

## ✅ 检查清单

部署前检查：
- [ ] Python 3.8+ 已安装
- [ ] pip 可用
- [ ] 模型文件已下载
- [ ] 依赖包已安装

测试前检查：
- [ ] 模型目录存在且包含 3 个文件（model.onnx, lexicon.txt, tokens.txt）
- [ ] sherpa_onnx 可以正常导入
- [ ] soundfile 可以正常导入

生产部署检查：
- [ ] 服务器满足最低配置要求（2GB+ 内存）
- [ ] 测试用例已通过
- [ ] 性能指标符合预期（RTF < 1.0）
- [ ] 错误处理机制已完善

---

**祝您使用愉快！** 🎉

如有问题，请参考 `部署指南.md` 或访问官方文档。

